{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_listing_id(soup):\n",
    "    script_tag = soup.find('script', string=re.compile(r'var infoVeiculo'))\n",
    "    match = re.search(r'var infoVeiculo = ({.*?});', script_tag.string)\n",
    "    return json.loads(match.group(1))['id']\n",
    "\n",
    "def _get_general_features(soup):\n",
    "    text = soup.find(\"div\", class_=\"d-flex flex-wrap w-100 mt-3\").p.get_text(strip=True)\n",
    "    return_list = [feature.strip() for feature in text.split(\"|\")]\n",
    "    return_list = (return_list + [np.nan] * 5)[:5]\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "def _get_header_info(soup):\n",
    "    h1 = soup.find(\"h1\", class_=\"text-uppercase desktop\")\n",
    "\n",
    "    maker = h1.contents[0].strip()\n",
    "    model = h1.find(\"span\").get_text(strip=True)\n",
    "    other_info = h1.find(\"span\", class_=\"gray\").get_text(strip=True)\n",
    "    other_info = other_info.replace(\"\\xa0\", \" \")\n",
    "\n",
    "    other_info = [feature.strip() for feature in other_info.split(' ')]\n",
    "    return_list = [maker, model]\n",
    "    return_list = return_list + other_info\n",
    "\n",
    "    return_list = (return_list + [np.nan] * 5)[:5]\n",
    "\n",
    "    return return_list\n",
    "\n",
    "def _get_li_features(soup):\n",
    "    features = soup.find_all(\"li\", class_=\"list-style-none mb-3\")\n",
    "    return [feature.get_text(strip=True) for feature in features]\n",
    "\n",
    "def _get_seller_description(soup):\n",
    "    text = soup.find(\"p\", itemprop=\"description\")\n",
    "    return text.get_text(separator=\"\\n\", strip=True).replace(\"\\n\", \" \") if text else np.nan\n",
    "    \n",
    "def _get_image(soup):\n",
    "    text = soup.find('meta', {'property': 'og:image'})\n",
    "    return text.get('content') if text else np.nan\n",
    "    \n",
    "def _get_city(soup):\n",
    "    text = soup.find(\"p\", class_=\"mb-0 mt-3 d-flex align-items-baseline\")\n",
    "    return text.get_text(strip=True) if text else np.nan\n",
    "\n",
    "def _get_price(soup):\n",
    "    text = soup.find('p', class_='mb-0 pr-2 text-color-1')\n",
    "    return text.get_text(strip=True) if text else np.nan\n",
    "\n",
    "def _get_year(soup):\n",
    "    text = soup.find('p', class_='mb-0 px-2 meio')\n",
    "    return text.get_text(strip=True) if text else np.nan\n",
    "\n",
    "def get_car_features(url):\n",
    "    response = requests.get(url) \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    general_features = _get_general_features(soup)\n",
    "    header_info = _get_header_info(soup)\n",
    "    li_features = _get_li_features(soup)\n",
    "    seller_description = _get_seller_description(soup)\n",
    "    image = _get_image(soup)\n",
    "    year = _get_year(soup)\n",
    "    city = _get_city(soup)\n",
    "    price = _get_price(soup)\n",
    "\n",
    "    features_dict = {\n",
    "        'id': _get_listing_id(soup),\n",
    "        'title': soup.title.string,\n",
    "        'seller_description': seller_description,\n",
    "        'link': soup.find('meta', {'property': 'og:url'}).get('content'), \n",
    "        'image': image,\n",
    "        'maker': header_info[0],\n",
    "        'model': header_info[1],\n",
    "        'year': year,\n",
    "        'engine': header_info[2],\n",
    "        'valves': header_info[3],\n",
    "        'transmission': general_features[0],\n",
    "        'fuel_type': general_features[1],\n",
    "        'body_type': general_features[2],\n",
    "        'doors': header_info[4],\n",
    "        'color': general_features[3],\n",
    "        'mileage': general_features[4],\n",
    "        'other_fatures': li_features,\n",
    "        'city': city,\n",
    "        'price': price,\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([features_dict])\n",
    "\n",
    "# url = 'https://carrosp.com.br/comprar/sedan/hyundai/hb-20-sedan/1.0-12v-4p-flex-vision/2022/7241455/'\n",
    "# get_car_features(url)\n",
    "\n",
    "# url = 'https://carrosp.com.br/comprar/sedan/toyota/yaris-sedan/1.5-16v-4p-flex-xl/2023/7241914/'\n",
    "# get_car_features(url)['image'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_id(url):\n",
    "    # Extract numeric ID at the end of the URL using regex\n",
    "    match = re.search(r'/(\\d+)/$', url)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def _get_unique_items(input_list):\n",
    "    unique_items = []\n",
    "    for item in input_list:\n",
    "        if item not in unique_items:\n",
    "            unique_items.append(item)\n",
    "    return unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "#url = 'https://carrosp.com.br/carros/'\n",
    "\n",
    "price_range = [0, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000, 80000, \n",
    "               85000, 90000, 95000, 100000, 105000, 110000, 115000, 120000, 130000, 140000, 150000, 300000]\n",
    "\n",
    "for i in range(len(price_range) - 1):\n",
    "#for i in range(1):\n",
    "\n",
    "    # Fix URL an open it\n",
    "    url = f\"https://carrosp.com.br/carros/todos/?revendedor=0&revendedor=S&particular=0&particular=S&tipo_id=1&marca_id=&ano1=&ano2=&zero=0&zero=S&usado=0&usado=S&kmIni=&kmFim=&precoIni={price_range[i]}&precoFim={price_range[i+1]}&idForm=formBuscaVeiculo&id=&cor_id=&combustivel_id=&distancia=100&cidadeNome=&cidade_id=&nocidade=1&\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Locate the element containing the number of vehicles and extract it\n",
    "    element = driver.find_element(By.CSS_SELECTOR, \"p.qtde-result.font-weight-bold\")\n",
    "    text = element.text  \n",
    "    number = int(text.split()[0]) \n",
    "    iters = round(number/21) + 1\n",
    "\n",
    "    print(f\"Price Range: R$ {price_range[i]} - R$ {price_range[i+1]} - {number} Listings - {iters} Iterations\")\n",
    "\n",
    "    car_listings = list()\n",
    "\n",
    "    for iter in range(iters):\n",
    "        # Scroll down and up to load listings\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        driver.execute_script(\"window.scrollBy(0, -1100);\")\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        # if iter%10 == 0: # Doing it to egt partial data so in dont lose anything\n",
    "        #     elements = driver.find_elements(By.CSS_SELECTOR, \"a.titulo.novajanela.mb-1\")\n",
    "        #     \n",
    "        #     for element in tqdm(elements):\n",
    "        #         href = element.get_attribute(\"href\")\n",
    "        #         if href:\n",
    "        #             car_listings.append(href)\n",
    "\n",
    "    # Repeat to process to fetch all possible data\n",
    "    elements = driver.find_elements(By.CSS_SELECTOR, \"a.titulo.novajanela.mb-1\")\n",
    "    \n",
    "    print(\"Final fetch\")\n",
    "    for element in tqdm(elements):\n",
    "        href = element.get_attribute(\"href\")\n",
    "        if href:\n",
    "            car_listings.append(href)\n",
    "\n",
    "    car_listings = list(set(car_listings))\n",
    "    \n",
    "    # Writes listings url\n",
    "    with open(\"listings.txt\", \"a\") as file:\n",
    "        for url in car_listings:\n",
    "            file.write(url + \"\\n\")\n",
    "\n",
    "driver.quit()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
